{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNXeFUThXWfJAsMF/v2P2ER",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anik-Adnan/Natural-Language-Processing/blob/main/Advanced_Lexical_Processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üìñ Session Introduction\n",
        "\n",
        "### Introduction\n",
        "In the previous session, you learnt all the **basic lexical processing techniques** such as:\n",
        "- Removing stop words  \n",
        "- Tokenization  \n",
        "- Stemming and lemmatization  \n",
        "- Creating Bag-of-Words and TF-IDF models  \n",
        "- Building a spam detector  \n",
        "\n",
        "These preprocessing steps are applicable in **almost every text analytics application**.\n",
        "\n",
        "Even after applying these preprocessing steps, **a lot of noise is still present** in the data. Examples include:\n",
        "- Spelling mistakes (by accident or intentionally, e.g., 'lol', 'awsum')  \n",
        "- Spelling variations due to pronunciation differences (e.g., Bangalore vs Bengaluru)  \n",
        "\n",
        "In this session, you‚Äôll learn how to:\n",
        "- **Identify and process incorrectly spelt words**  \n",
        "- **Handle spelling variations**  \n",
        "- Tokenize text **efficiently**, especially for multi-word terms like:\n",
        "  - ‚ÄòHong Kong‚Äô  \n",
        "  - ‚ÄòCalvin Klein‚Äô  \n",
        "  - ‚ÄòInternational Institute of Information Technology‚Äô  \n",
        "\n",
        "Simple tokenization splits these into separate words, but such terms should be preserved as **single tokens**. This session will cover techniques to build **intelligent tokenizers**.\n",
        "\n",
        "---\n",
        "\n",
        "### üîπ What you‚Äôll learn in this session\n",
        "1. **Phonetic hashing and the Soundex algorithm** to handle different pronunciations of a word.  \n",
        "2. **Minimum-edit-distance algorithm** and building a spell corrector.  \n",
        "3. **Pointwise Mutual Information (PMI)** score to preserve multi-word terms as single tokens.  \n",
        "\n",
        "---\n",
        "\n",
        "### üìå Prerequisites\n",
        "- Knowledge of the **previous session** and the **previous module**.  \n",
        "- No additional prerequisites are required for this session.  \n"
      ],
      "metadata": {
        "id": "7wYCrs6QT4ka"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üõ†Ô∏è Canonicalisation\n",
        "\n",
        "### Introduction\n",
        "In the last session, you learnt techniques to **reduce a word to its base form**, specifically:  \n",
        "- **Stemming**  \n",
        "- **Lemmatization**  \n",
        "\n",
        "These techniques are part of a broader concept called **canonicalisation**.  \n",
        "\n",
        "**Canonicalisation**: The process of reducing a word to its base form.  \n",
        "- **Stemming:** Reduces a word to its root form.  \n",
        "- **Lemmatization:** Reduces a word to its lemma.  \n",
        "- Both root and lemma are **base forms of inflected words**.\n",
        "\n",
        "---\n",
        "\n",
        "### üîπ Limitations of Stemming and Lemmatization\n",
        "Some cases cannot be handled effectively by stemming or lemmatization alone. For example, **misspelled words**:\n",
        "\n",
        "Corpus contains two misspelt versions of *disappearing*:  \n"
      ],
      "metadata": {
        "id": "Rc_wfRd3UlMX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üîä Phonetic Hashing\n",
        "\n",
        "### Introduction\n",
        "Certain words have **different pronunciations** in different languages, which often leads to **different spellings** in a text corpus. Examples include:  \n",
        "- City names: `Delhi` vs `Dilli`  \n",
        "- Personal names: `Agrawal` with multiple spellings  \n",
        "- Dish names and other proper nouns  \n",
        "\n",
        "Applying **stemming or lemmatization** alone does not solve the problem of **redundant tokens**, because multiple variants of the same word still exist. To address this, we use **phonetic hashing**.\n",
        "\n",
        "---\n",
        "\n",
        "### üîπ What is Phonetic Hashing?\n",
        "Phonetic hashing groups **words with similar sounds (phonemes)** into a single bucket and assigns them a **common hash code**.  \n",
        "\n",
        "Example:  \n",
        "- `Dilli` and `Delhi` ‚Üí same hash code  \n",
        "\n",
        "This ensures that all variations of a word **map to the same canonical form**, reducing redundancy.\n",
        "\n",
        "---\n",
        "\n",
        "### üîπ Soundex Algorithm\n",
        "The most popular phonetic hashing method is the **American Soundex algorithm**.  \n",
        "- Maps words that sound similar to a **common code**  \n",
        "- Works across dialects and languages  \n",
        "- Handles **British vs American spellings**  \n",
        "\n",
        "---\n",
        "\n",
        "### üîπ Example: Soundex of \"Mississippi\"\n",
        "\n",
        "1. **First letter retained:**  \n",
        "   - Input: `Mississippi`  \n",
        "   - Code starts with: `M`  \n",
        "\n",
        "2. **Map consonants (except first letter):**  \n",
        "   - Vowels remain as is (`A, E, I, O, U`)  \n",
        "   - Letters `H, W, Y` are **ignored/unencoded**  \n",
        "   - Consonants mapped to numbers ‚Üí `MI22I22I11I`  \n",
        "\n",
        "3. **Remove vowels:**  \n",
        "   - Remove all `I`s ‚Üí `M222211`  \n",
        "\n",
        "4. **Merge consecutive duplicates:**  \n",
        "   - `222` ‚Üí `2`  \n",
        "   - `11` ‚Üí `1`  \n",
        "   - Code becomes ‚Üí `M21`  \n",
        "\n",
        "5. **Force four-character code:**  \n",
        "   - If less than four characters, **pad with zeros**  \n",
        "   - If more than four characters, **truncate from the right**  \n",
        "   - `M21` ‚Üí pad ‚Üí `M210`  \n",
        "\n",
        "**Final Soundex code:**  \n"
      ],
      "metadata": {
        "id": "aX_vC2PjVD7a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ‚ùì True/False Question\n",
        "\n",
        "**Statement:**  \n",
        "The first letter of the Soundex of **Mumbai** and **Bombay** is the same.  \n",
        "\n",
        "**Answer:**  \n",
        "**False**  \n",
        "\n",
        "**Explanation:**  \n",
        "- Soundex retains the **first letter of the word** as the first character of the code.  \n",
        "- `Mumbai` ‚Üí Soundex starts with **M**  \n",
        "- `Bombay` ‚Üí Soundex starts with **B**  \n",
        "- Since **M ‚â† B**, the first letters are **not the same**.\n"
      ],
      "metadata": {
        "id": "QPIJ7bzVVO9j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ucHMtZcbTxw8"
      },
      "outputs": [],
      "source": []
    }
  ]
}